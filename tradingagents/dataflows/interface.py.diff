# æ–‡ä»¶å·®å¼‚æŠ¥å‘Š
# å½“å‰æ–‡ä»¶: tradingagents\dataflows\interface.py
# ä¸­æ–‡ç‰ˆæ–‡ä»¶: TradingAgentsCN\tradingagents\dataflows\interface.py
# ç”Ÿæˆæ—¶é—´: å‘¨æ—¥ 2025/07/06

--- current/interface.py+++ chinese_version/interface.py@@ -1,5 +1,6 @@ from typing import Annotated, Dict
 from .reddit_utils import fetch_top_from_category
+from .chinese_finance_utils import get_chinese_social_sentiment
 from .yfin_utils import *
 from .stockstats_utils import *
 from .googlenews_utils import *
@@ -43,7 +44,14 @@     result = get_data_in_range(ticker, before, curr_date, "news_data", DATA_DIR)
 
     if len(result) == 0:
-        return ""
+        error_msg = f"âš ï¸ æ— æ³•è·å–{ticker}çš„æ–°é—»æ•°æ® ({before} åˆ° {curr_date})\n"
+        error_msg += f"å¯èƒ½çš„åŸå› ï¼š\n"
+        error_msg += f"1. æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨æˆ–è·¯å¾„é…ç½®é”™è¯¯\n"
+        error_msg += f"2. æŒ‡å®šæ—¥æœŸèŒƒå›´å†…æ²¡æœ‰æ–°é—»æ•°æ®\n"
+        error_msg += f"3. éœ€è¦å…ˆä¸‹è½½æˆ–æ›´æ–°Finnhubæ–°é—»æ•°æ®\n"
+        error_msg += f"å»ºè®®ï¼šæ£€æŸ¥æ•°æ®ç›®å½•é…ç½®æˆ–é‡æ–°è·å–æ–°é—»æ•°æ®"
+        print(f"ğŸ“° [DEBUG] {error_msg}")
+        return error_msg
 
     combined_result = ""
     for day, data in result.items():
@@ -772,36 +780,217 @@     return response.output[1].content[0].text
 
 
+def get_fundamentals_finnhub(ticker, curr_date):
+    """
+    ä½¿ç”¨Finnhub APIè·å–è‚¡ç¥¨åŸºæœ¬é¢æ•°æ®ä½œä¸ºOpenAIçš„å¤‡é€‰æ–¹æ¡ˆ
+    Args:
+        ticker (str): è‚¡ç¥¨ä»£ç 
+        curr_date (str): å½“å‰æ—¥æœŸï¼Œæ ¼å¼ä¸ºyyyy-mm-dd
+    Returns:
+        str: æ ¼å¼åŒ–çš„åŸºæœ¬é¢æ•°æ®æŠ¥å‘Š
+    """
+    try:
+        import finnhub
+        import os
+        from .cache_manager import get_cache
+        
+        # æ£€æŸ¥ç¼“å­˜
+        cache = get_cache()
+        cached_key = cache.find_cached_fundamentals_data(ticker, data_source="finnhub")
+        if cached_key:
+            cached_data = cache.load_fundamentals_data(cached_key)
+            if cached_data:
+                print(f"ğŸ’¾ [DEBUG] ä»ç¼“å­˜åŠ è½½FinnhubåŸºæœ¬é¢æ•°æ®: {ticker}")
+                return cached_data
+        
+        # è·å–Finnhub APIå¯†é’¥
+        api_key = os.getenv('FINNHUB_API_KEY')
+        if not api_key:
+            return "é”™è¯¯ï¼šæœªé…ç½®FINNHUB_API_KEYç¯å¢ƒå˜é‡"
+        
+        # åˆå§‹åŒ–Finnhubå®¢æˆ·ç«¯
+        finnhub_client = finnhub.Client(api_key=api_key)
+        
+        print(f"ğŸ“Š [DEBUG] ä½¿ç”¨Finnhub APIè·å– {ticker} çš„åŸºæœ¬é¢æ•°æ®...")
+        
+        # è·å–åŸºæœ¬è´¢åŠ¡æ•°æ®
+        try:
+            basic_financials = finnhub_client.company_basic_financials(ticker, 'all')
+        except Exception as e:
+            print(f"âŒ [DEBUG] FinnhubåŸºæœ¬è´¢åŠ¡æ•°æ®è·å–å¤±è´¥: {str(e)}")
+            basic_financials = None
+        
+        # è·å–å…¬å¸æ¦‚å†µ
+        try:
+            company_profile = finnhub_client.company_profile2(symbol=ticker)
+        except Exception as e:
+            print(f"âŒ [DEBUG] Finnhubå…¬å¸æ¦‚å†µè·å–å¤±è´¥: {str(e)}")
+            company_profile = None
+        
+        # è·å–æ”¶ç›Šæ•°æ®
+        try:
+            earnings = finnhub_client.company_earnings(ticker, limit=4)
+        except Exception as e:
+            print(f"âŒ [DEBUG] Finnhubæ”¶ç›Šæ•°æ®è·å–å¤±è´¥: {str(e)}")
+            earnings = None
+        
+        # æ ¼å¼åŒ–æŠ¥å‘Š
+        report = f"# {ticker} åŸºæœ¬é¢åˆ†ææŠ¥å‘Šï¼ˆFinnhubæ•°æ®æºï¼‰\n\n"
+        report += f"**æ•°æ®è·å–æ—¶é—´**: {curr_date}\n"
+        report += f"**æ•°æ®æ¥æº**: Finnhub API\n\n"
+        
+        # å…¬å¸æ¦‚å†µéƒ¨åˆ†
+        if company_profile:
+            report += "## å…¬å¸æ¦‚å†µ\n"
+            report += f"- **å…¬å¸åç§°**: {company_profile.get('name', 'N/A')}\n"
+            report += f"- **è¡Œä¸š**: {company_profile.get('finnhubIndustry', 'N/A')}\n"
+            report += f"- **å›½å®¶**: {company_profile.get('country', 'N/A')}\n"
+            report += f"- **è´§å¸**: {company_profile.get('currency', 'N/A')}\n"
+            report += f"- **å¸‚å€¼**: {company_profile.get('marketCapitalization', 'N/A')} ç™¾ä¸‡ç¾å…ƒ\n"
+            report += f"- **æµé€šè‚¡æ•°**: {company_profile.get('shareOutstanding', 'N/A')} ç™¾ä¸‡è‚¡\n\n"
+        
+        # åŸºæœ¬è´¢åŠ¡æŒ‡æ ‡
+        if basic_financials and 'metric' in basic_financials:
+            metrics = basic_financials['metric']
+            report += "## å…³é”®è´¢åŠ¡æŒ‡æ ‡\n"
+            report += "| æŒ‡æ ‡ | æ•°å€¼ |\n"
+            report += "|------|------|\n"
+            
+            # ä¼°å€¼æŒ‡æ ‡
+            if 'peBasicExclExtraTTM' in metrics:
+                report += f"| å¸‚ç›ˆç‡ (PE) | {metrics['peBasicExclExtraTTM']:.2f} |\n"
+            if 'psAnnual' in metrics:
+                report += f"| å¸‚é”€ç‡ (PS) | {metrics['psAnnual']:.2f} |\n"
+            if 'pbAnnual' in metrics:
+                report += f"| å¸‚å‡€ç‡ (PB) | {metrics['pbAnnual']:.2f} |\n"
+            
+            # ç›ˆåˆ©èƒ½åŠ›æŒ‡æ ‡
+            if 'roeTTM' in metrics:
+                report += f"| å‡€èµ„äº§æ”¶ç›Šç‡ (ROE) | {metrics['roeTTM']:.2f}% |\n"
+            if 'roaTTM' in metrics:
+                report += f"| æ€»èµ„äº§æ”¶ç›Šç‡ (ROA) | {metrics['roaTTM']:.2f}% |\n"
+            if 'netProfitMarginTTM' in metrics:
+                report += f"| å‡€åˆ©æ¶¦ç‡ | {metrics['netProfitMarginTTM']:.2f}% |\n"
+            
+            # è´¢åŠ¡å¥åº·æŒ‡æ ‡
+            if 'currentRatioAnnual' in metrics:
+                report += f"| æµåŠ¨æ¯”ç‡ | {metrics['currentRatioAnnual']:.2f} |\n"
+            if 'totalDebt/totalEquityAnnual' in metrics:
+                report += f"| è´Ÿå€ºæƒç›Šæ¯” | {metrics['totalDebt/totalEquityAnnual']:.2f} |\n"
+            
+            report += "\n"
+        
+        # æ”¶ç›Šå†å²
+        if earnings:
+            report += "## æ”¶ç›Šå†å²\n"
+            report += "| å­£åº¦ | å®é™…EPS | é¢„æœŸEPS | å·®å¼‚ |\n"
+            report += "|------|---------|---------|------|\n"
+            for earning in earnings[:4]:  # æ˜¾ç¤ºæœ€è¿‘4ä¸ªå­£åº¦
+                actual = earning.get('actual', 'N/A')
+                estimate = earning.get('estimate', 'N/A')
+                period = earning.get('period', 'N/A')
+                surprise = earning.get('surprise', 'N/A')
+                report += f"| {period} | {actual} | {estimate} | {surprise} |\n"
+            report += "\n"
+        
+        # æ•°æ®å¯ç”¨æ€§è¯´æ˜
+        report += "## æ•°æ®è¯´æ˜\n"
+        report += "- æœ¬æŠ¥å‘Šä½¿ç”¨Finnhub APIæä¾›çš„å®˜æ–¹è´¢åŠ¡æ•°æ®\n"
+        report += "- æ•°æ®æ¥æºäºå…¬å¸è´¢æŠ¥å’ŒSECæ–‡ä»¶\n"
+        report += "- TTMè¡¨ç¤ºè¿‡å»12ä¸ªæœˆæ•°æ®\n"
+        report += "- Annualè¡¨ç¤ºå¹´åº¦æ•°æ®\n\n"
+        
+        if not basic_financials and not company_profile and not earnings:
+            report += "âš ï¸ **è­¦å‘Š**: æ— æ³•è·å–è¯¥è‚¡ç¥¨çš„åŸºæœ¬é¢æ•°æ®ï¼Œå¯èƒ½åŸå› ï¼š\n"
+            report += "- è‚¡ç¥¨ä»£ç ä¸æ­£ç¡®\n"
+            report += "- Finnhub APIé™åˆ¶\n"
+            report += "- è¯¥è‚¡ç¥¨æš‚æ— åŸºæœ¬é¢æ•°æ®\n"
+        
+        # ä¿å­˜åˆ°ç¼“å­˜
+        if report and len(report) > 100:  # åªæœ‰å½“æŠ¥å‘Šæœ‰å®é™…å†…å®¹æ—¶æ‰ç¼“å­˜
+            cache.save_fundamentals_data(ticker, report, data_source="finnhub")
+        
+        print(f"ğŸ“Š [DEBUG] FinnhubåŸºæœ¬é¢æ•°æ®è·å–å®Œæˆï¼ŒæŠ¥å‘Šé•¿åº¦: {len(report)}")
+        return report
+        
+    except ImportError:
+        return "é”™è¯¯ï¼šæœªå®‰è£…finnhub-pythonåº“ï¼Œè¯·è¿è¡Œ: pip install finnhub-python"
+    except Exception as e:
+        print(f"âŒ [DEBUG] FinnhubåŸºæœ¬é¢æ•°æ®è·å–å¤±è´¥: {str(e)}")
+        return f"FinnhubåŸºæœ¬é¢æ•°æ®è·å–å¤±è´¥: {str(e)}"
+
+
 def get_fundamentals_openai(ticker, curr_date):
-    config = get_config()
-    client = OpenAI(base_url=config["backend_url"])
-
-    response = client.responses.create(
-        model=config["quick_think_llm"],
-        input=[
-            {
-                "role": "system",
-                "content": [
-                    {
-                        "type": "input_text",
-                        "text": f"Can you search Fundamental for discussions on {ticker} during of the month before {curr_date} to the month of {curr_date}. Make sure you only get the data posted during that period. List as a table, with PE/PS/Cash flow/ etc",
-                    }
-                ],
-            }
-        ],
-        text={"format": {"type": "text"}},
-        reasoning={},
-        tools=[
-            {
-                "type": "web_search_preview",
-                "user_location": {"type": "approximate"},
-                "search_context_size": "low",
-            }
-        ],
-        temperature=1,
-        max_output_tokens=4096,
-        top_p=1,
-        store=True,
-    )
-
-    return response.output[1].content[0].text
+    """
+    è·å–è‚¡ç¥¨åŸºæœ¬é¢æ•°æ®ï¼Œä¼˜å…ˆä½¿ç”¨OpenAIï¼Œå¤±è´¥æ—¶å›é€€åˆ°Finnhub API
+    æ”¯æŒç¼“å­˜æœºåˆ¶ä»¥æé«˜æ€§èƒ½
+    Args:
+        ticker (str): è‚¡ç¥¨ä»£ç 
+        curr_date (str): å½“å‰æ—¥æœŸï¼Œæ ¼å¼ä¸ºyyyy-mm-dd
+    Returns:
+        str: åŸºæœ¬é¢æ•°æ®æŠ¥å‘Š
+    """
+    try:
+        from .cache_manager import get_cache
+        
+        # æ£€æŸ¥ç¼“å­˜ - ä¼˜å…ˆæ£€æŸ¥OpenAIç¼“å­˜
+        cache = get_cache()
+        cached_key = cache.find_cached_fundamentals_data(ticker, data_source="openai")
+        if cached_key:
+            cached_data = cache.load_fundamentals_data(cached_key)
+            if cached_data:
+                print(f"ğŸ’¾ [DEBUG] ä»ç¼“å­˜åŠ è½½OpenAIåŸºæœ¬é¢æ•°æ®: {ticker}")
+                return cached_data
+        
+        config = get_config()
+        
+        # æ£€æŸ¥æ˜¯å¦é…ç½®äº†OpenAIç›¸å…³è®¾ç½®
+        if not config.get("backend_url") or not config.get("quick_think_llm"):
+            print(f"ğŸ“Š [DEBUG] OpenAIé…ç½®ä¸å®Œæ•´ï¼Œç›´æ¥ä½¿ç”¨Finnhub API")
+            return get_fundamentals_finnhub(ticker, curr_date)
+        
+        print(f"ğŸ“Š [DEBUG] å°è¯•ä½¿ç”¨OpenAIè·å– {ticker} çš„åŸºæœ¬é¢æ•°æ®...")
+        
+        client = OpenAI(base_url=config["backend_url"])
+
+        response = client.responses.create(
+            model=config["quick_think_llm"],
+            input=[
+                {
+                    "role": "system",
+                    "content": [
+                        {
+                            "type": "input_text",
+                            "text": f"Can you search Fundamental for discussions on {ticker} during of the month before {curr_date} to the month of {curr_date}. Make sure you only get the data posted during that period. List as a table, with PE/PS/Cash flow/ etc",
+                        }
+                    ],
+                }
+            ],
+            text={"format": {"type": "text"}},
+            reasoning={},
+            tools=[
+                {
+                    "type": "web_search_preview",
+                    "user_location": {"type": "approximate"},
+                    "search_context_size": "low",
+                }
+            ],
+            temperature=1,
+            max_output_tokens=4096,
+            top_p=1,
+            store=True,
+        )
+
+        result = response.output[1].content[0].text
+        
+        # ä¿å­˜åˆ°ç¼“å­˜
+        if result and len(result) > 100:  # åªæœ‰å½“ç»“æœæœ‰å®é™…å†…å®¹æ—¶æ‰ç¼“å­˜
+            cache.save_fundamentals_data(ticker, result, data_source="openai")
+        
+        print(f"ğŸ“Š [DEBUG] OpenAIåŸºæœ¬é¢æ•°æ®è·å–æˆåŠŸï¼Œé•¿åº¦: {len(result)}")
+        return result
+        
+    except Exception as e:
+        print(f"âŒ [DEBUG] OpenAIåŸºæœ¬é¢æ•°æ®è·å–å¤±è´¥: {str(e)}")
+        print(f"ğŸ“Š [DEBUG] å›é€€åˆ°Finnhub API...")
+        return get_fundamentals_finnhub(ticker, curr_date)
